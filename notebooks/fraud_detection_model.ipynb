{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a502765e",
   "metadata": {},
   "source": [
    "# Fraud Detection Model - Isolation Forest\n",
    "## A Machine Learning Approach to Detecting Transaction Anomalies\n",
    "\n",
    "This notebook demonstrates the implementation and evaluation of an Isolation Forest model for detecting fraudulent transactions in financial data. The model uses unsupervised learning to identify anomalies based on transaction patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd8447a",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8a8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf1c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic transaction data\n",
    "from src.fraud_detection import generate_synthetic_data\n",
    "\n",
    "df = generate_synthetic_data(n=5000, fraud_count=150)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few records:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(f\"\\nFraud Distribution:\")\n",
    "print(df['is_fraud'].value_counts())\n",
    "print(f\"Fraud Rate: {df['is_fraud'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4490c",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ad2bf",
   "metadata": {},
   "source": [
    "## 3. Model Training - Isolation Forest\n",
    "\n",
    "**Why Isolation Forest?**\n",
    "- Effective for anomaly detection in high-dimensional spaces\n",
    "- Doesn't require labeled training data for normal samples\n",
    "- Computationally efficient and scalable\n",
    "- Works well for fraud detection with imbalanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd43a50",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fdc62a",
   "metadata": {},
   "source": [
    "## 5. Visualizations and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631db7a6",
   "metadata": {},
   "source": [
    "## 6. ROC Curve and Additional Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e812c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, -anomaly_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curve', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(loc=\"lower right\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Anomaly Score Distribution\n",
    "axes[1].hist(anomaly_scores[y_true == 0], bins=50, alpha=0.6, label='Normal', color='green')\n",
    "axes[1].hist(anomaly_scores[y_true == 1], bins=50, alpha=0.6, label='Fraud', color='red')\n",
    "axes[1].set_xlabel('Anomaly Score (Decision Function)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Anomaly Score Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f2ded0",
   "metadata": {},
   "source": [
    "## 7. Key Findings and Conclusions\n",
    "\n",
    "### Model Performance Summary\n",
    "- **Algorithm**: Isolation Forest (Unsupervised Anomaly Detection)\n",
    "- **Strengths**: \n",
    "  - Effective at detecting outliers in high-dimensional spaces\n",
    "  - Works well with imbalanced datasets\n",
    "  - Interpretable decision functions\n",
    "- **Use Case**: Real-time fraud detection in transaction systems\n",
    "\n",
    "### Key Insights\n",
    "1. **Data Characteristics**: The synthetic data shows clear fraud patterns with high-value transactions occurring during late-night hours (0-3 AM)\n",
    "2. **Model Effectiveness**: The Isolation Forest successfully identifies the injected fraud signal\n",
    "3. **Threshold Selection**: The contamination parameter (3%) aligns with the actual fraud rate in the dataset\n",
    "\n",
    "### Next Steps for Production\n",
    "- Validate on real-world transaction data\n",
    "- Implement threshold tuning based on business requirements (sensitivity vs. specificity)\n",
    "- Consider ensemble methods combining multiple algorithms\n",
    "- Deploy with monitoring for model drift\n",
    "- Integrate with real-time transaction processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584bf31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "df_model = df.copy()\n",
    "\n",
    "# Encode categorical variable (transaction_type)\n",
    "le = LabelEncoder()\n",
    "df_model['transaction_type_encoded'] = le.fit_transform(df_model['transaction_type'])\n",
    "\n",
    "# Display encoding mapping\n",
    "print(\"Transaction Type Encoding:\")\n",
    "for i, type_name in enumerate(le.classes_):\n",
    "    print(f\"  {i}: {type_name}\")\n",
    "\n",
    "# Select features and target\n",
    "features = ['amount', 'time_of_day', 'transaction_type_encoded']\n",
    "X = df_model[features].copy()\n",
    "y_true = df_model['is_fraud'].copy()\n",
    "\n",
    "# Standardize features (important for Isolation Forest)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=features)\n",
    "\n",
    "print(f\"\\nFeature Matrix Shape: {X.shape}\")\n",
    "print(f\"Features: {list(X.columns)}\")\n",
    "print(f\"\\nFeature Statistics:\")\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6df539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Isolation Forest model\n",
    "print(\"Training Isolation Forest Model...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "model = IsolationForest(\n",
    "    n_estimators=200,        # Number of isolation trees\n",
    "    contamination=0.03,       # Expected proportion of outliers (3%)\n",
    "    random_state=42,          # For reproducibility\n",
    "    n_jobs=-1                 # Use all CPU cores\n",
    ")\n",
    "\n",
    "model.fit(X)\n",
    "\n",
    "# Get anomaly scores and predictions\n",
    "anomaly_scores = model.decision_function(X)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Convert predictions: normal=1 → 0, anomaly=-1 → 1\n",
    "y_pred = np.where(predictions == -1, 1, 0)\n",
    "\n",
    "print(\"Model Training Complete!\")\n",
    "print(f\"Model Parameters: {model.get_params()}\")\n",
    "print(f\"\\nPrediction Distribution:\")\n",
    "print(f\"  Normal Transactions: {(y_pred == 0).sum()}\")\n",
    "print(f\"  Flagged as Fraud: {(y_pred == 1).sum()}\")\n",
    "print(f\"  Flagged Rate: {(y_pred == 1).mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb70f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Model Evaluation\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"  True Negatives: {tn}\")\n",
    "print(f\"  False Positives: {fp}\")\n",
    "print(f\"  False Negatives: {fn}\")\n",
    "print(f\"  True Positives: {tp}\")\n",
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"\\nKey Metrics:\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall (Sensitivity): {recall:.4f}\")\n",
    "print(f\"  F1-Score: {f1_score:.4f}\")\n",
    "\n",
    "# ROC-AUC Score\n",
    "try:\n",
    "    roc_auc = roc_auc_score(y_true, -anomaly_scores)  # Use negative scores for ROC\n",
    "    print(f\"  ROC-AUC Score: {roc_auc:.4f}\")\n",
    "except:\n",
    "    print(\"  ROC-AUC Score: Could not compute\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Normal', 'Fraud']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a585fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "cm_labels = np.array([['True Neg', 'False Pos'], ['False Neg', 'True Pos']])\n",
    "sns.heatmap(cm, annot=cm_labels, fmt='', cmap='Blues', cbar=False, ax=axes[0, 0],\n",
    "            xticklabels=['Normal', 'Fraud'], yticklabels=['Normal', 'Fraud'])\n",
    "axes[0, 0].set_title('Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('True Label')\n",
    "axes[0, 0].set_xlabel('Predicted Label')\n",
    "\n",
    "# 2. Transaction Amount Distribution (Normal vs Fraud)\n",
    "axes[0, 1].hist(df[df['is_fraud'] == 0]['amount'], bins=40, alpha=0.6, label='Normal', color='green')\n",
    "axes[0, 1].hist(df[df['is_fraud'] == 1]['amount'], bins=40, alpha=0.6, label='Fraud', color='red')\n",
    "axes[0, 1].set_title('Transaction Amount Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Amount ($)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_xlim(0, 200000)\n",
    "\n",
    "# 3. Average Amount by Class\n",
    "avg_amount = df.groupby('is_fraud')['amount'].mean()\n",
    "colors = ['green', 'red']\n",
    "axes[1, 0].bar(['Normal', 'Fraud'], avg_amount.values, color=colors, alpha=0.7)\n",
    "axes[1, 0].set_title('Average Transaction Amount by Class', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Average Amount ($)')\n",
    "for i, v in enumerate(avg_amount.values):\n",
    "    axes[1, 0].text(i, v + 1000, f'${v:,.0f}', ha='center', fontweight='bold')\n",
    "\n",
    "# 4. Fraud by Time of Day\n",
    "fraud_by_hour = df.groupby('time_of_day')['is_fraud'].agg(['sum', 'count'])\n",
    "fraud_by_hour['rate'] = (fraud_by_hour['sum'] / fraud_by_hour['count'] * 100).fillna(0)\n",
    "axes[1, 1].plot(fraud_by_hour.index, fraud_by_hour['rate'], marker='o', linewidth=2, markersize=8, color='red')\n",
    "axes[1, 1].set_title('Fraud Rate by Hour of Day', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Hour of Day')\n",
    "axes[1, 1].set_ylabel('Fraud Rate (%)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualizations generated successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
